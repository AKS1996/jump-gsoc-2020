{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QPTH\n",
    "Differentiating sum of solution using optnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qpth.qp import QPFunction\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[2., 1., 0.],\n",
    "              [1., 2., 1.],\n",
    "              [0., 1., 2.]])\n",
    "q = np.array([0., 0., 0.])\n",
    "G = np.array([[-1., -2., -3.], [-1., -1., 0.]])\n",
    "h = np.array([-4., -1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, Q, G, h = [torch.Tensor(x) for x in [q, Q, G, h]]\n",
    "\n",
    "A, b = [torch.Tensor()] * 2\n",
    "\n",
    "q, Q, G, h, A, b = [Variable(x) for x in [q, Q, G, h, A, b]]\n",
    "Q.requires_grad = True\n",
    "q.requires_grad = True\n",
    "G.requires_grad = True\n",
    "h.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpf = QPFunction()\n",
    "zhat_b = qpf(Q, q, G, h, A, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5714, 0.4286, 0.8571]], grad_fn=<QPFunctionFnBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhat_b  # solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zhat_b.backward(torch.Tensor([[1.1, 0.9, 0.8]]))\n",
    "zhat_b.backward(torch.Tensor([[1.0, 1.0, 1.0]])) # setting dl/dz = ones(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = [x.grad.data.squeeze(0).cpu().numpy() for x in [Q, q, G, h]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12244895,  0.01530609, -0.11224488],\n",
       "       [ 0.01530609,  0.09183674,  0.07653058],\n",
       "       [-0.11224488,  0.07653058, -0.06122449]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQ = grads[0]\n",
    "dQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2142857 ,  0.21428567, -0.07142857], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq = grads[1]\n",
    "dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05102035, 0.30612245, 0.255102  ],\n",
       "       [0.06122443, 0.36734694, 0.3061224 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dG = grads[2]\n",
    "dG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.35714284, -0.4285714 ], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh = grads[3]\n",
    "dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPYLayers\n",
    "Differentiating using cvxpylayers. Note that we can't differentiate w.r.t `Q` matrix as defining it as a parameter violates DPP constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import tensorflow as tf\n",
    "from cvxpylayers.tensorflow import CvxpyLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "m = 2\n",
    "\n",
    "x = cp.Variable(n)\n",
    "Q = np.array([[2., 1., 0.],\n",
    "              [1., 2., 1.],\n",
    "              [0., 1., 2.]])\n",
    "_q = np.array([0., 0., 0.])\n",
    "_G = np.array([[-1., -2., -3.], [-1., -1., 0.]])\n",
    "_h = np.array([-4., -1.])\n",
    "q = cp.Parameter(n)\n",
    "G = cp.Parameter((m, n))\n",
    "h = cp.Parameter(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = [G@x <= h]\n",
    "objective = cp.Minimize(0.5*cp.quad_form(x, Q) + q.T @ x)\n",
    "problem = cp.Problem(objective, constraints)\n",
    "assert problem.is_dpp()\n",
    "\n",
    "# cvxpylayers computes gradient of sum of solution wrt params\n",
    "# i.e. u don't need to pass dl/dz, its fixed as tf.ones(n)\n",
    "\n",
    "cvxpylayer = CvxpyLayer(problem, parameters=[q, G, h], variables=[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_tf = tf.Variable(\n",
    "    tf.convert_to_tensor(\n",
    "        _q, \n",
    "        np.float32\n",
    "    )\n",
    ")\n",
    "\n",
    "h_tf = tf.Variable(\n",
    "    tf.convert_to_tensor(\n",
    "        _h, \n",
    "        np.float32\n",
    "    )\n",
    ")\n",
    "\n",
    "G_tf = tf.Variable(\n",
    "    tf.convert_to_tensor(\n",
    "        _G, \n",
    "        np.float32\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "  solution, = cvxpylayer(q_tf, G_tf, h_tf)\n",
    "  summed_solution = tf.math.reduce_sum(solution)\n",
    "    \n",
    "grads = tape.gradient(summed_solution, [q_tf, G_tf, h_tf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([-0.21428571,  0.21428571, -0.07142857])>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       "array([[0.05102041, 0.30612245, 0.25510204],\n",
       "       [0.06122449, 0.36734694, 0.30612245]])>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([-0.35714286, -0.42857143])>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('procol': venv)",
   "language": "python",
   "name": "python36964bitprocolvenv3d5a78e847ac487da652a96deb972468"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
