{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check python version\n",
    "import sys\n",
    "v = sys.version_info\n",
    "assert v.major == 3 and v.minor >= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/.pyenv/versions/procol/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/akshay/.pyenv/versions/procol/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# check packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load IRIS dataset\n",
    "content = '{\"5.1\":{\"0\":4.9,\"1\":4.7,\"2\":4.6,\"3\":5.0,\"4\":5.4,\"5\":4.6,\"6\":5.0,\"7\":4.4,\"8\":4.9,\"9\":5.4,\"10\":4.8,\"11\":4.8,\"12\":4.3,\"13\":5.8,\"14\":5.7,\"15\":5.4,\"16\":5.1,\"17\":5.7,\"18\":5.1,\"19\":5.4,\"20\":5.1,\"21\":4.6,\"22\":5.1,\"23\":4.8,\"24\":5.0,\"25\":5.0,\"26\":5.2,\"27\":5.2,\"28\":4.7,\"29\":4.8,\"30\":5.4,\"31\":5.2,\"32\":5.5,\"33\":4.9,\"34\":5.0,\"35\":5.5,\"36\":4.9,\"37\":4.4,\"38\":5.1,\"39\":5.0,\"40\":4.5,\"41\":4.4,\"42\":5.0,\"43\":5.1,\"44\":4.8,\"45\":5.1,\"46\":4.6,\"47\":5.3,\"48\":5.0,\"49\":7.0,\"50\":6.4,\"51\":6.9,\"52\":5.5,\"53\":6.5,\"54\":5.7,\"55\":6.3,\"56\":4.9,\"57\":6.6,\"58\":5.2,\"59\":5.0,\"60\":5.9,\"61\":6.0,\"62\":6.1,\"63\":5.6,\"64\":6.7,\"65\":5.6,\"66\":5.8,\"67\":6.2,\"68\":5.6,\"69\":5.9,\"70\":6.1,\"71\":6.3,\"72\":6.1,\"73\":6.4,\"74\":6.6,\"75\":6.8,\"76\":6.7,\"77\":6.0,\"78\":5.7,\"79\":5.5,\"80\":5.5,\"81\":5.8,\"82\":6.0,\"83\":5.4,\"84\":6.0,\"85\":6.7,\"86\":6.3,\"87\":5.6,\"88\":5.5,\"89\":5.5,\"90\":6.1,\"91\":5.8,\"92\":5.0,\"93\":5.6,\"94\":5.7,\"95\":5.7,\"96\":6.2,\"97\":5.1,\"98\":5.7,\"99\":6.3,\"100\":5.8,\"101\":7.1,\"102\":6.3,\"103\":6.5,\"104\":7.6,\"105\":4.9,\"106\":7.3,\"107\":6.7,\"108\":7.2,\"109\":6.5,\"110\":6.4,\"111\":6.8,\"112\":5.7,\"113\":5.8,\"114\":6.4,\"115\":6.5,\"116\":7.7,\"117\":7.7,\"118\":6.0,\"119\":6.9,\"120\":5.6,\"121\":7.7,\"122\":6.3,\"123\":6.7,\"124\":7.2,\"125\":6.2,\"126\":6.1,\"127\":6.4,\"128\":7.2,\"129\":7.4,\"130\":7.9,\"131\":6.4,\"132\":6.3,\"133\":6.1,\"134\":7.7,\"135\":6.3,\"136\":6.4,\"137\":6.0,\"138\":6.9,\"139\":6.7,\"140\":6.9,\"141\":5.8,\"142\":6.8,\"143\":6.7,\"144\":6.7,\"145\":6.3,\"146\":6.5,\"147\":6.2,\"148\":5.9},\"3.5\":{\"0\":3.0,\"1\":3.2,\"2\":3.1,\"3\":3.6,\"4\":3.9,\"5\":3.4,\"6\":3.4,\"7\":2.9,\"8\":3.1,\"9\":3.7,\"10\":3.4,\"11\":3.0,\"12\":3.0,\"13\":4.0,\"14\":4.4,\"15\":3.9,\"16\":3.5,\"17\":3.8,\"18\":3.8,\"19\":3.4,\"20\":3.7,\"21\":3.6,\"22\":3.3,\"23\":3.4,\"24\":3.0,\"25\":3.4,\"26\":3.5,\"27\":3.4,\"28\":3.2,\"29\":3.1,\"30\":3.4,\"31\":4.1,\"32\":4.2,\"33\":3.1,\"34\":3.2,\"35\":3.5,\"36\":3.1,\"37\":3.0,\"38\":3.4,\"39\":3.5,\"40\":2.3,\"41\":3.2,\"42\":3.5,\"43\":3.8,\"44\":3.0,\"45\":3.8,\"46\":3.2,\"47\":3.7,\"48\":3.3,\"49\":3.2,\"50\":3.2,\"51\":3.1,\"52\":2.3,\"53\":2.8,\"54\":2.8,\"55\":3.3,\"56\":2.4,\"57\":2.9,\"58\":2.7,\"59\":2.0,\"60\":3.0,\"61\":2.2,\"62\":2.9,\"63\":2.9,\"64\":3.1,\"65\":3.0,\"66\":2.7,\"67\":2.2,\"68\":2.5,\"69\":3.2,\"70\":2.8,\"71\":2.5,\"72\":2.8,\"73\":2.9,\"74\":3.0,\"75\":2.8,\"76\":3.0,\"77\":2.9,\"78\":2.6,\"79\":2.4,\"80\":2.4,\"81\":2.7,\"82\":2.7,\"83\":3.0,\"84\":3.4,\"85\":3.1,\"86\":2.3,\"87\":3.0,\"88\":2.5,\"89\":2.6,\"90\":3.0,\"91\":2.6,\"92\":2.3,\"93\":2.7,\"94\":3.0,\"95\":2.9,\"96\":2.9,\"97\":2.5,\"98\":2.8,\"99\":3.3,\"100\":2.7,\"101\":3.0,\"102\":2.9,\"103\":3.0,\"104\":3.0,\"105\":2.5,\"106\":2.9,\"107\":2.5,\"108\":3.6,\"109\":3.2,\"110\":2.7,\"111\":3.0,\"112\":2.5,\"113\":2.8,\"114\":3.2,\"115\":3.0,\"116\":3.8,\"117\":2.6,\"118\":2.2,\"119\":3.2,\"120\":2.8,\"121\":2.8,\"122\":2.7,\"123\":3.3,\"124\":3.2,\"125\":2.8,\"126\":3.0,\"127\":2.8,\"128\":3.0,\"129\":2.8,\"130\":3.8,\"131\":2.8,\"132\":2.8,\"133\":2.6,\"134\":3.0,\"135\":3.4,\"136\":3.1,\"137\":3.0,\"138\":3.1,\"139\":3.1,\"140\":3.1,\"141\":2.7,\"142\":3.2,\"143\":3.3,\"144\":3.0,\"145\":2.5,\"146\":3.0,\"147\":3.4,\"148\":3.0},\"1.4\":{\"0\":1.4,\"1\":1.3,\"2\":1.5,\"3\":1.4,\"4\":1.7,\"5\":1.4,\"6\":1.5,\"7\":1.4,\"8\":1.5,\"9\":1.5,\"10\":1.6,\"11\":1.4,\"12\":1.1,\"13\":1.2,\"14\":1.5,\"15\":1.3,\"16\":1.4,\"17\":1.7,\"18\":1.5,\"19\":1.7,\"20\":1.5,\"21\":1.0,\"22\":1.7,\"23\":1.9,\"24\":1.6,\"25\":1.6,\"26\":1.5,\"27\":1.4,\"28\":1.6,\"29\":1.6,\"30\":1.5,\"31\":1.5,\"32\":1.4,\"33\":1.5,\"34\":1.2,\"35\":1.3,\"36\":1.5,\"37\":1.3,\"38\":1.5,\"39\":1.3,\"40\":1.3,\"41\":1.3,\"42\":1.6,\"43\":1.9,\"44\":1.4,\"45\":1.6,\"46\":1.4,\"47\":1.5,\"48\":1.4,\"49\":4.7,\"50\":4.5,\"51\":4.9,\"52\":4.0,\"53\":4.6,\"54\":4.5,\"55\":4.7,\"56\":3.3,\"57\":4.6,\"58\":3.9,\"59\":3.5,\"60\":4.2,\"61\":4.0,\"62\":4.7,\"63\":3.6,\"64\":4.4,\"65\":4.5,\"66\":4.1,\"67\":4.5,\"68\":3.9,\"69\":4.8,\"70\":4.0,\"71\":4.9,\"72\":4.7,\"73\":4.3,\"74\":4.4,\"75\":4.8,\"76\":5.0,\"77\":4.5,\"78\":3.5,\"79\":3.8,\"80\":3.7,\"81\":3.9,\"82\":5.1,\"83\":4.5,\"84\":4.5,\"85\":4.7,\"86\":4.4,\"87\":4.1,\"88\":4.0,\"89\":4.4,\"90\":4.6,\"91\":4.0,\"92\":3.3,\"93\":4.2,\"94\":4.2,\"95\":4.2,\"96\":4.3,\"97\":3.0,\"98\":4.1,\"99\":6.0,\"100\":5.1,\"101\":5.9,\"102\":5.6,\"103\":5.8,\"104\":6.6,\"105\":4.5,\"106\":6.3,\"107\":5.8,\"108\":6.1,\"109\":5.1,\"110\":5.3,\"111\":5.5,\"112\":5.0,\"113\":5.1,\"114\":5.3,\"115\":5.5,\"116\":6.7,\"117\":6.9,\"118\":5.0,\"119\":5.7,\"120\":4.9,\"121\":6.7,\"122\":4.9,\"123\":5.7,\"124\":6.0,\"125\":4.8,\"126\":4.9,\"127\":5.6,\"128\":5.8,\"129\":6.1,\"130\":6.4,\"131\":5.6,\"132\":5.1,\"133\":5.6,\"134\":6.1,\"135\":5.6,\"136\":5.5,\"137\":4.8,\"138\":5.4,\"139\":5.6,\"140\":5.1,\"141\":5.1,\"142\":5.9,\"143\":5.7,\"144\":5.2,\"145\":5.0,\"146\":5.2,\"147\":5.4,\"148\":5.1},\"0.2\":{\"0\":0.2,\"1\":0.2,\"2\":0.2,\"3\":0.2,\"4\":0.4,\"5\":0.3,\"6\":0.2,\"7\":0.2,\"8\":0.1,\"9\":0.2,\"10\":0.2,\"11\":0.1,\"12\":0.1,\"13\":0.2,\"14\":0.4,\"15\":0.4,\"16\":0.3,\"17\":0.3,\"18\":0.3,\"19\":0.2,\"20\":0.4,\"21\":0.2,\"22\":0.5,\"23\":0.2,\"24\":0.2,\"25\":0.4,\"26\":0.2,\"27\":0.2,\"28\":0.2,\"29\":0.2,\"30\":0.4,\"31\":0.1,\"32\":0.2,\"33\":0.1,\"34\":0.2,\"35\":0.2,\"36\":0.1,\"37\":0.2,\"38\":0.2,\"39\":0.3,\"40\":0.3,\"41\":0.2,\"42\":0.6,\"43\":0.4,\"44\":0.3,\"45\":0.2,\"46\":0.2,\"47\":0.2,\"48\":0.2,\"49\":1.4,\"50\":1.5,\"51\":1.5,\"52\":1.3,\"53\":1.5,\"54\":1.3,\"55\":1.6,\"56\":1.0,\"57\":1.3,\"58\":1.4,\"59\":1.0,\"60\":1.5,\"61\":1.0,\"62\":1.4,\"63\":1.3,\"64\":1.4,\"65\":1.5,\"66\":1.0,\"67\":1.5,\"68\":1.1,\"69\":1.8,\"70\":1.3,\"71\":1.5,\"72\":1.2,\"73\":1.3,\"74\":1.4,\"75\":1.4,\"76\":1.7,\"77\":1.5,\"78\":1.0,\"79\":1.1,\"80\":1.0,\"81\":1.2,\"82\":1.6,\"83\":1.5,\"84\":1.6,\"85\":1.5,\"86\":1.3,\"87\":1.3,\"88\":1.3,\"89\":1.2,\"90\":1.4,\"91\":1.2,\"92\":1.0,\"93\":1.3,\"94\":1.2,\"95\":1.3,\"96\":1.3,\"97\":1.1,\"98\":1.3,\"99\":2.5,\"100\":1.9,\"101\":2.1,\"102\":1.8,\"103\":2.2,\"104\":2.1,\"105\":1.7,\"106\":1.8,\"107\":1.8,\"108\":2.5,\"109\":2.0,\"110\":1.9,\"111\":2.1,\"112\":2.0,\"113\":2.4,\"114\":2.3,\"115\":1.8,\"116\":2.2,\"117\":2.3,\"118\":1.5,\"119\":2.3,\"120\":2.0,\"121\":2.0,\"122\":1.8,\"123\":2.1,\"124\":1.8,\"125\":1.8,\"126\":1.8,\"127\":2.1,\"128\":1.6,\"129\":1.9,\"130\":2.0,\"131\":2.2,\"132\":1.5,\"133\":1.4,\"134\":2.3,\"135\":2.4,\"136\":1.8,\"137\":1.8,\"138\":2.1,\"139\":2.4,\"140\":2.3,\"141\":1.9,\"142\":2.3,\"143\":2.5,\"144\":2.3,\"145\":1.9,\"146\":2.0,\"147\":2.3,\"148\":1.8},\"Iris-setosa\":{\"0\":\"Iris-setosa\",\"1\":\"Iris-setosa\",\"2\":\"Iris-setosa\",\"3\":\"Iris-setosa\",\"4\":\"Iris-setosa\",\"5\":\"Iris-setosa\",\"6\":\"Iris-setosa\",\"7\":\"Iris-setosa\",\"8\":\"Iris-setosa\",\"9\":\"Iris-setosa\",\"10\":\"Iris-setosa\",\"11\":\"Iris-setosa\",\"12\":\"Iris-setosa\",\"13\":\"Iris-setosa\",\"14\":\"Iris-setosa\",\"15\":\"Iris-setosa\",\"16\":\"Iris-setosa\",\"17\":\"Iris-setosa\",\"18\":\"Iris-setosa\",\"19\":\"Iris-setosa\",\"20\":\"Iris-setosa\",\"21\":\"Iris-setosa\",\"22\":\"Iris-setosa\",\"23\":\"Iris-setosa\",\"24\":\"Iris-setosa\",\"25\":\"Iris-setosa\",\"26\":\"Iris-setosa\",\"27\":\"Iris-setosa\",\"28\":\"Iris-setosa\",\"29\":\"Iris-setosa\",\"30\":\"Iris-setosa\",\"31\":\"Iris-setosa\",\"32\":\"Iris-setosa\",\"33\":\"Iris-setosa\",\"34\":\"Iris-setosa\",\"35\":\"Iris-setosa\",\"36\":\"Iris-setosa\",\"37\":\"Iris-setosa\",\"38\":\"Iris-setosa\",\"39\":\"Iris-setosa\",\"40\":\"Iris-setosa\",\"41\":\"Iris-setosa\",\"42\":\"Iris-setosa\",\"43\":\"Iris-setosa\",\"44\":\"Iris-setosa\",\"45\":\"Iris-setosa\",\"46\":\"Iris-setosa\",\"47\":\"Iris-setosa\",\"48\":\"Iris-setosa\",\"49\":\"Iris-versicolor\",\"50\":\"Iris-versicolor\",\"51\":\"Iris-versicolor\",\"52\":\"Iris-versicolor\",\"53\":\"Iris-versicolor\",\"54\":\"Iris-versicolor\",\"55\":\"Iris-versicolor\",\"56\":\"Iris-versicolor\",\"57\":\"Iris-versicolor\",\"58\":\"Iris-versicolor\",\"59\":\"Iris-versicolor\",\"60\":\"Iris-versicolor\",\"61\":\"Iris-versicolor\",\"62\":\"Iris-versicolor\",\"63\":\"Iris-versicolor\",\"64\":\"Iris-versicolor\",\"65\":\"Iris-versicolor\",\"66\":\"Iris-versicolor\",\"67\":\"Iris-versicolor\",\"68\":\"Iris-versicolor\",\"69\":\"Iris-versicolor\",\"70\":\"Iris-versicolor\",\"71\":\"Iris-versicolor\",\"72\":\"Iris-versicolor\",\"73\":\"Iris-versicolor\",\"74\":\"Iris-versicolor\",\"75\":\"Iris-versicolor\",\"76\":\"Iris-versicolor\",\"77\":\"Iris-versicolor\",\"78\":\"Iris-versicolor\",\"79\":\"Iris-versicolor\",\"80\":\"Iris-versicolor\",\"81\":\"Iris-versicolor\",\"82\":\"Iris-versicolor\",\"83\":\"Iris-versicolor\",\"84\":\"Iris-versicolor\",\"85\":\"Iris-versicolor\",\"86\":\"Iris-versicolor\",\"87\":\"Iris-versicolor\",\"88\":\"Iris-versicolor\",\"89\":\"Iris-versicolor\",\"90\":\"Iris-versicolor\",\"91\":\"Iris-versicolor\",\"92\":\"Iris-versicolor\",\"93\":\"Iris-versicolor\",\"94\":\"Iris-versicolor\",\"95\":\"Iris-versicolor\",\"96\":\"Iris-versicolor\",\"97\":\"Iris-versicolor\",\"98\":\"Iris-versicolor\",\"99\":\"Iris-virginica\",\"100\":\"Iris-virginica\",\"101\":\"Iris-virginica\",\"102\":\"Iris-virginica\",\"103\":\"Iris-virginica\",\"104\":\"Iris-virginica\",\"105\":\"Iris-virginica\",\"106\":\"Iris-virginica\",\"107\":\"Iris-virginica\",\"108\":\"Iris-virginica\",\"109\":\"Iris-virginica\",\"110\":\"Iris-virginica\",\"111\":\"Iris-virginica\",\"112\":\"Iris-virginica\",\"113\":\"Iris-virginica\",\"114\":\"Iris-virginica\",\"115\":\"Iris-virginica\",\"116\":\"Iris-virginica\",\"117\":\"Iris-virginica\",\"118\":\"Iris-virginica\",\"119\":\"Iris-virginica\",\"120\":\"Iris-virginica\",\"121\":\"Iris-virginica\",\"122\":\"Iris-virginica\",\"123\":\"Iris-virginica\",\"124\":\"Iris-virginica\",\"125\":\"Iris-virginica\",\"126\":\"Iris-virginica\",\"127\":\"Iris-virginica\",\"128\":\"Iris-virginica\",\"129\":\"Iris-virginica\",\"130\":\"Iris-virginica\",\"131\":\"Iris-virginica\",\"132\":\"Iris-virginica\",\"133\":\"Iris-virginica\",\"134\":\"Iris-virginica\",\"135\":\"Iris-virginica\",\"136\":\"Iris-virginica\",\"137\":\"Iris-virginica\",\"138\":\"Iris-virginica\",\"139\":\"Iris-virginica\",\"140\":\"Iris-virginica\",\"141\":\"Iris-virginica\",\"142\":\"Iris-virginica\",\"143\":\"Iris-virginica\",\"144\":\"Iris-virginica\",\"145\":\"Iris-virginica\",\"146\":\"Iris-virginica\",\"147\":\"Iris-virginica\",\"148\":\"Iris-virginica\"}}'\n",
    "dataset = pd.read_json(content)\n",
    "dataset.columns = ['sepal_length','sepal_width','petal_length','petal_width','species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solving usual NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        X = self.fc3(X)\n",
    "        X = self.softmax(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss [1.134224]\n",
      "number of epoch 5 loss [1.118426]\n",
      "number of epoch 10 loss [1.1017094]\n",
      "number of epoch 15 loss [1.0835718]\n",
      "number of epoch 20 loss [1.0633184]\n",
      "number of epoch 25 loss [1.0407481]\n",
      "number of epoch 30 loss [1.0170678]\n",
      "number of epoch 35 loss [0.9941053]\n",
      "prediction accuracy 0.6416666666666667\n",
      "macro precision 0.48716302952503215\n",
      "micro precision 0.6416666666666667\n",
      "macro recall 0.6666666666666666\n",
      "micro recall 0.6416666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/.pyenv/versions/procol/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "# transform species to numerics\n",
    "dataset.loc[dataset.species=='Iris-setosa', 'species'] = 0\n",
    "dataset.loc[dataset.species=='Iris-versicolor', 'species'] = 1\n",
    "dataset.loc[dataset.species=='Iris-virginica', 'species'] = 2\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(dataset[dataset.columns[0:4]].values,\n",
    "                                                    dataset.species.values, test_size=0.8)\n",
    "\n",
    "# wrap up with Variable in pytorch\n",
    "train_X = Variable(torch.Tensor(train_X).float())\n",
    "test_X = Variable(torch.Tensor(test_X).float())\n",
    "train_y = Variable(torch.Tensor(train_y).long())\n",
    "test_y = Variable(torch.Tensor(test_y).long())\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(40):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(train_X)\n",
    "    loss = criterion(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print ('number of epoch', epoch, 'loss', loss.data.numpy().ravel())\n",
    "\n",
    "predict_out = net(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "print ('prediction accuracy', accuracy_score(test_y.data, predict_y.data))\n",
    "print ('macro precision', precision_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro precision', precision_score(test_y.data, predict_y.data, average='micro'))\n",
    "print ('macro recall', recall_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro recall', recall_score(test_y.data, predict_y.data, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN with Cvxlayer's softmax  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 3)\n",
    "\n",
    "        # defining softmax as an optimization problem\n",
    "        _x = cp.Parameter(3)\n",
    "        _y = cp.Variable(3)\n",
    "        obj = cp.Minimize(-_x.T*_y - cp.sum(cp.entr(_y)))\n",
    "        cons = [np.ones(3, dtype=np.float32).T*_y == 1.]\n",
    "        prob = cp.Problem(obj, cons)\n",
    "        self.softmax = CvxpyLayer(prob, parameters=[_x], variables=[_y])\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        X = self.fc3(X)\n",
    "        X = self.softmax(X)[0]\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/.pyenv/versions/procol/lib/python3.6/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n",
      "/home/akshay/.pyenv/versions/procol/lib/python3.6/site-packages/cvxpy/expressions/expression.py:503: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n",
      "/home/akshay/.pyenv/versions/procol/lib/python3.6/site-packages/cvxpy/expressions/expression.py:503: UserWarning: \n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "\n",
      "  warnings.warn(__STAR_MATMUL_WARNING__, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epoch 0 loss [1.0890237]\n",
      "number of epoch 5 loss [1.0657148]\n",
      "number of epoch 10 loss [1.042408]\n",
      "number of epoch 15 loss [1.0212156]\n",
      "number of epoch 20 loss [1.0017418]\n",
      "number of epoch 25 loss [0.9832171]\n",
      "number of epoch 30 loss [0.9655601]\n",
      "number of epoch 35 loss [0.9489396]\n",
      "prediction accuracy 0.6416666666666667\n",
      "macro precision 0.49603174603174605\n",
      "micro precision 0.6416666666666667\n",
      "macro recall 0.6666666666666666\n",
      "micro recall 0.6416666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/.pyenv/versions/procol/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# transform species to numerics\n",
    "dataset.loc[dataset.species=='Iris-setosa', 'species'] = 0\n",
    "dataset.loc[dataset.species=='Iris-versicolor', 'species'] = 1\n",
    "dataset.loc[dataset.species=='Iris-virginica', 'species'] = 2\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(dataset[dataset.columns[0:4]].values,\n",
    "                                                    dataset.species.values, test_size=0.8)\n",
    "\n",
    "# wrap up with Variable in pytorch\n",
    "train_X = Variable(torch.Tensor(train_X).float())\n",
    "test_X = Variable(torch.Tensor(test_X).float())\n",
    "train_y = Variable(torch.Tensor(train_y).long())\n",
    "test_y = Variable(torch.Tensor(test_y).long())\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(40):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(train_X)\n",
    "    loss = criterion(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print ('number of epoch', epoch, 'loss', loss.data.numpy().ravel())\n",
    "\n",
    "predict_out = net(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "print ('prediction accuracy', accuracy_score(test_y.data, predict_y.data))\n",
    "print ('macro precision', precision_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro precision', precision_score(test_y.data, predict_y.data, average='micro'))\n",
    "print ('macro recall', recall_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro recall', recall_score(test_y.data, predict_y.data, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('procol': venv)",
   "language": "python",
   "name": "python36964bitprocolvenv3d5a78e847ac487da652a96deb972468"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
