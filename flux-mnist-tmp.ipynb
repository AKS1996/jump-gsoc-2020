{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ChainRules\n",
    "using DiffOpt\n",
    "using Flux\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated\n",
    "using OSQP\n",
    "using JuMP\n",
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = Flux.Data.MNIST.images()\n",
    "labels = Flux.Data.MNIST.labels();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare data\n",
    "# Preprocessing\n",
    "X = hcat(float.(reshape.(imgs, :))...) #stack all the images\n",
    "Y = onehotbatch(labels, 0:9); # just a common way to encode categorical variables\n",
    "\n",
    "test_X = hcat(float.(reshape.(Flux.Data.MNIST.images(:test), :))...)\n",
    "test_Y = onehotbatch(Flux.Data.MNIST.labels(:test), 0:9);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myRelu (generic function with 2 methods)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myRelu(y)\n",
    "    N = length(y)\n",
    "    # create model\n",
    "    model = Model(() -> diff_optimizer(OSQP.Optimizer))\n",
    "    @variable(model, x[1:N])\n",
    "    @constraint(model, x .>= 0.0)\n",
    "    @objective(\n",
    "        model,\n",
    "        Min,\n",
    "        x'x -2x'y + y'y,\n",
    "    )\n",
    "\n",
    "    optimize!(model)\n",
    "\n",
    "    x̂ = value.(x)\n",
    "    return x̂\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rrule (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rrule(::typeof(myRelu), dx::Array{Float64})\n",
    "    N = length(y)\n",
    "    # create model\n",
    "    model = Model(() -> diff_optimizer(OSQP.Optimizer))\n",
    "    @variable(model, x[1:N])\n",
    "    @constraint(model, x .>= 0.0)\n",
    "    @objective(\n",
    "        model,\n",
    "        Min,\n",
    "        x'x -2x'y + y'y,\n",
    "    )\n",
    "\n",
    "    optimize!(model)\n",
    "\n",
    "    x̂ = value.(x)\n",
    "    \n",
    "    function _pullback(dx)\n",
    "        MOI.set.(\n",
    "            model,\n",
    "            DiffOpt.BackwardIn{MOI.VariablePrimal}(), \n",
    "            x,\n",
    "            dx\n",
    "        ) \n",
    "\n",
    "        # find grad\n",
    "        DiffOpt.backward(model)\n",
    "        \n",
    "        \n",
    "#         MOI.get.(\n",
    "#             model,\n",
    "#             DiffOpt.BackwardOut{DiffOpt.ConstraintCoefficient}(), \n",
    "#             x,\n",
    "#             cons,\n",
    "#         )\n",
    "        \n",
    "        dy = MOI.get.(\n",
    "            model,\n",
    "            DiffOpt.BackwardOut{DiffOpt.ConstraintConstant}(), \n",
    "            cons, \n",
    "        )\n",
    "        return NO_FIELDS, dy\n",
    "    end\n",
    "    return x̂, _pullback\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 64, myRelu), Dense(64, 10), NNlib.softmax)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Chain(\n",
    "    Dense(784, 64, myRelu),\n",
    "    Dense(64, 10),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#31 (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = crossentropy(m(x), y) \n",
    "opt = ADAM(); # popular stochastic gradient descent variant\n",
    "\n",
    "accuracy(x, y) = mean(onecold(m(x)) .== onecold(y)) # cute way to find average of correct guesses\n",
    "\n",
    "dataset = repeated((X,Y), 2) # repeat the data set\n",
    "evalcb = () -> @show(loss(X, Y)) # callback to show loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching zero(::Type{Adjoint{GenericAffExpr{Float64,VariableRef},Array{GenericAffExpr{Float64,VariableRef},1}}})\nClosest candidates are:\n  zero(!Matched::Type{LibGit2.GitHash}) at /buildworker/worker/package_linux32/build/usr/share/julia/stdlib/v1.0/LibGit2/src/oid.jl:220\n  zero(!Matched::Type{Pkg.Resolve.VersionWeights.VersionWeight}) at /buildworker/worker/package_linux32/build/usr/share/julia/stdlib/v1.0/Pkg/src/resolve/VersionWeights.jl:19\n  zero(!Matched::Type{Pkg.Resolve.MaxSum.FieldValues.FieldValue}) at /buildworker/worker/package_linux32/build/usr/share/julia/stdlib/v1.0/Pkg/src/resolve/FieldValues.jl:44\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching zero(::Type{Adjoint{GenericAffExpr{Float64,VariableRef},Array{GenericAffExpr{Float64,VariableRef},1}}})\nClosest candidates are:\n  zero(!Matched::Type{LibGit2.GitHash}) at /buildworker/worker/package_linux32/build/usr/share/julia/stdlib/v1.0/LibGit2/src/oid.jl:220\n  zero(!Matched::Type{Pkg.Resolve.VersionWeights.VersionWeight}) at /buildworker/worker/package_linux32/build/usr/share/julia/stdlib/v1.0/Pkg/src/resolve/VersionWeights.jl:19\n  zero(!Matched::Type{Pkg.Resolve.MaxSum.FieldValues.FieldValue}) at /buildworker/worker/package_linux32/build/usr/share/julia/stdlib/v1.0/Pkg/src/resolve/FieldValues.jl:44\n  ...",
      "",
      "Stacktrace:",
      " [1] promote_operation(::typeof(-), ::Type{GenericQuadExpr{Float64,VariableRef}}, ::Type{Adjoint{GenericAffExpr{Float64,VariableRef},Array{GenericAffExpr{Float64,VariableRef},1}}}) at /home/pika/.julia/packages/MutableArithmetics/DcLoq/src/interface.jl:24",
      " [2] promote_operation(::typeof(MutableArithmetics.sub_mul), ::Type, ::Type, ::Type, ::Type) at /home/pika/.julia/packages/MutableArithmetics/DcLoq/src/shortcuts.jl:63",
      " [3] mutability(::Type, ::Function, ::Type, ::Type, ::Type, ::Type) at /home/pika/.julia/packages/MutableArithmetics/DcLoq/src/interface.jl:156",
      " [4] mutability(::GenericQuadExpr{Float64,VariableRef}, ::Function, ::GenericQuadExpr{Float64,VariableRef}, ::Int32, ::Adjoint{VariableRef,Array{VariableRef,1}}, ::Float32) at /home/pika/.julia/packages/MutableArithmetics/DcLoq/src/interface.jl:162",
      " [5] operate!(::typeof(MutableArithmetics.sub_mul), ::GenericQuadExpr{Float64,VariableRef}, ::Int32, ::Adjoint{VariableRef,Array{VariableRef,1}}, ::Float32) at /home/pika/.julia/packages/MutableArithmetics/DcLoq/src/rewrite.jl:83",
      " [6] myRelu(::Float32) at /home/pika/.julia/packages/MutableArithmetics/DcLoq/src/rewrite.jl:279",
      " [7] #26 at /home/pika/.julia/packages/Tracker/cpxco/src/lib/array.jl:553 [inlined]",
      " [8] _broadcast_getindex_evalf at ./broadcast.jl:582 [inlined]",
      " [9] _broadcast_getindex at ./broadcast.jl:555 [inlined]",
      " [10] getindex at ./broadcast.jl:515 [inlined]",
      " [11] copy(::Base.Broadcast.Broadcasted{Base.Broadcast.DefaultArrayStyle{2},Tuple{Base.OneTo{Int32},Base.OneTo{Int32}},getfield(Base.Broadcast, Symbol(\"##26#28\")){getfield(Base.Broadcast, Symbol(\"##27#29\")){typeof(+),getfield(Base.Broadcast, Symbol(\"##9#10\")){getfield(Base.Broadcast, Symbol(\"##9#10\")){getfield(Base.Broadcast, Symbol(\"##11#12\"))}},getfield(Base.Broadcast, Symbol(\"##13#14\")){getfield(Base.Broadcast, Symbol(\"##13#14\")){getfield(Base.Broadcast, Symbol(\"##15#16\"))}},getfield(Base.Broadcast, Symbol(\"##5#6\")){getfield(Base.Broadcast, Symbol(\"##5#6\")){getfield(Base.Broadcast, Symbol(\"##3#4\"))}}},typeof(myRelu)},Tuple{Array{Float32,2},Array{Float32,1}}}) at ./broadcast.jl:790",
      " [12] materialize at ./broadcast.jl:756 [inlined]",
      " [13] broadcast at ./broadcast.jl:710 [inlined]",
      " [14] ∇broadcast(::getfield(Base.Broadcast, Symbol(\"##26#28\")){getfield(Base.Broadcast, Symbol(\"##27#29\")){typeof(+),getfield(Base.Broadcast, Symbol(\"##9#10\")){getfield(Base.Broadcast, Symbol(\"##9#10\")){getfield(Base.Broadcast, Symbol(\"##11#12\"))}},getfield(Base.Broadcast, Symbol(\"##13#14\")){getfield(Base.Broadcast, Symbol(\"##13#14\")){getfield(Base.Broadcast, Symbol(\"##15#16\"))}},getfield(Base.Broadcast, Symbol(\"##5#6\")){getfield(Base.Broadcast, Symbol(\"##5#6\")){getfield(Base.Broadcast, Symbol(\"##3#4\"))}}},typeof(myRelu)}, ::TrackedArray{…,Array{Float32,2}}, ::TrackedArray{…,Array{Float32,1}}) at /home/pika/.julia/packages/Tracker/cpxco/src/lib/array.jl:509",
      " [15] copy(::Base.Broadcast.Broadcasted{Tracker.TrackedStyle,Tuple{Base.OneTo{Int32},Base.OneTo{Int32}},typeof(myRelu),Tuple{Base.Broadcast.Broadcasted{Tracker.TrackedStyle,Nothing,typeof(+),Tuple{TrackedArray{…,Array{Float32,2}},TrackedArray{…,Array{Float32,1}}}}}}) at /home/pika/.julia/packages/Tracker/cpxco/src/lib/array.jl:540",
      " [16] materialize at ./broadcast.jl:756 [inlined]",
      " [17] Dense at /home/pika/.julia/packages/Flux/qXNjB/src/layers/basic.jl:99 [inlined]",
      " [18] Dense at /home/pika/.julia/packages/Flux/qXNjB/src/layers/basic.jl:110 [inlined]",
      " [19] (::Dense{typeof(myRelu),TrackedArray{…,Array{Float32,2}},TrackedArray{…,Array{Float32,1}}})(::Array{Float64,2}) at /home/pika/.julia/packages/Flux/qXNjB/src/layers/basic.jl:113",
      " [20] applychain(::Tuple{Dense{typeof(myRelu),TrackedArray{…,Array{Float32,2}},TrackedArray{…,Array{Float32,1}}},Dense{typeof(identity),TrackedArray{…,Array{Float32,2}},TrackedArray{…,Array{Float32,1}}},typeof(softmax)}, ::Array{Float64,2}) at /home/pika/.julia/packages/Flux/qXNjB/src/layers/basic.jl:31",
      " [21] (::Chain{Tuple{Dense{typeof(myRelu),TrackedArray{…,Array{Float32,2}},TrackedArray{…,Array{Float32,1}}},Dense{typeof(identity),TrackedArray{…,Array{Float32,2}},TrackedArray{…,Array{Float32,1}}},typeof(softmax)}})(::Array{Float64,2}) at /home/pika/.julia/packages/Flux/qXNjB/src/layers/basic.jl:33",
      " [22] loss(::Array{Float64,2}, ::Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}) at ./In[23]:1",
      " [23] #15 at /home/pika/.julia/packages/Flux/qXNjB/src/optimise/train.jl:72 [inlined]",
      " [24] gradient_(::getfield(Flux.Optimise, Symbol(\"##15#21\")){typeof(loss),Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}, ::Tracker.Params) at /home/pika/.julia/packages/Tracker/cpxco/src/back.jl:97",
      " [25] #gradient#24(::Bool, ::Function, ::Function, ::Tracker.Params) at /home/pika/.julia/packages/Tracker/cpxco/src/back.jl:164",
      " [26] gradient at /home/pika/.julia/packages/Tracker/cpxco/src/back.jl:164 [inlined]",
      " [27] macro expansion at /home/pika/.julia/packages/Flux/qXNjB/src/optimise/train.jl:71 [inlined]",
      " [28] macro expansion at /home/pika/.julia/packages/Juno/oLB1d/src/progress.jl:134 [inlined]",
      " [29] #train!#12(::getfield(Flux, Symbol(\"#throttled#18\")){getfield(Flux, Symbol(\"##throttled#10#14\")){Bool,Bool,getfield(Main, Symbol(\"##31#32\")),Int32}}, ::Function, ::Function, ::Tracker.Params, ::Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}}, ::ADAM) at /home/pika/.julia/packages/Flux/qXNjB/src/optimise/train.jl:69",
      " [30] (::getfield(Flux.Optimise, Symbol(\"#kw##train!\")))(::NamedTuple{(:cb,),Tuple{getfield(Flux, Symbol(\"#throttled#18\")){getfield(Flux, Symbol(\"##throttled#10#14\")){Bool,Bool,getfield(Main, Symbol(\"##31#32\")),Int32}}}}, ::typeof(Flux.Optimise.train!), ::Function, ::Tracker.Params, ::Base.Iterators.Take{Base.Iterators.Repeated{Tuple{Array{Float64,2},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}}}}, ::ADAM) at ./none:0",
      " [31] top-level scope at In[24]:1"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, params(m), dataset, opt, cb = throttle(evalcb, 5)); #took me ~5 minutes to train on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(X, Y) = 0.24961666666666665\n",
      "accuracy(test_X, test_Y) = 0.2567\n"
     ]
    }
   ],
   "source": [
    "@show accuracy(X,Y)\n",
    "@show accuracy(test_X, test_Y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.4",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
